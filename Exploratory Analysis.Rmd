---
title: "Exploratory Analysis"
author: "Richard G. Gardiner"
date: "2/21/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r}
library(tidyverse)
library(tidytext)
library(readxl)
library(statebins)
library(geofacet)
library(cowplot)
library(textdata)

theme_set(theme_light())

lexicon_afinn()
lexicon_bing()
lexicon_loughran()
```

```{r}
gavel <- read_excel("Gavel to Gavel dataset.xlsx") %>%
  filter(Year > 2007,
         Year < 2020)

political_culture <- read_csv("political culture.csv")
professional <- read_csv("ncsl professionalization.csv")
legislative_control <- read_excel("Legislative Control.xlsx")
```


# Gavel to Gavel dataset

How many bills are in my dataset?
```{r}
gavel %>%
  count()
```

How man bills over time?
```{r}
gavel %>%
  count(Year) %>%
  ggplot(aes(x = Year, y = n)) +
  geom_line() +
  labs(y = "Total Number of Bills") +
  scale_x_discrete(limits = c(2008, 2010, 2012, 2014, 2016))

# ggsave("Bills over year.jpeg")
```

```{r}
gavel %>%
  count(Year, State) %>%
  spread(Year, n) %>%
  mutate(diff = (`2009` - `2008`)) %>%
  # arrange(desc(diff))
  summarize(median_diff = median(diff, na.rm = TRUE),
            mean_diff = mean(diff, na.rm = TRUE))
  
  

```

Bills by Type
```{r}
curbing_type <- gavel %>%
  filter(curbing == 1) %>%
  count(Type) %>%
  filter(Type != "No Legislation") %>%
  mutate(Type = fct_reorder(Type, n)) %>%
  ggplot(aes(x = Type, y = n)) +
  geom_col() +
  labs(x = "", y = "Number of Bills", title = "Court Curbing Bills") +
  coord_flip()

not_curbing_type <- gavel %>%
  filter(curbing == 0) %>%
  count(Type) %>%
  filter(Type != "No Legislation") %>%
  mutate(Type = fct_reorder(Type, n)) %>%
  ggplot(aes(x = Type, y = n)) +
  geom_col() +
  labs(x = "", y = "Number of Bills", title = "All Other Bills") +
  coord_flip()

plot_grid(curbing_type, not_curbing_type)

# ggsave("Number of Bills by Type.jpeg")
```


Map of # of bills by state
```{r}
library(usmap)
library(maps)


all_states <- map_data("state")

us.cities %>%
  filter(capital == 2) %>%
  left_join(gavel, by = c("country.etc" = "State")) %>%
  filter(!(country.etc %in% c("AK", "HI"))) %>%
  count(long, lat, Elected) %>%
  ggplot() +
  geom_point(aes(x = long, y = lat, size = n, color = Elected)) +
  borders("state") +
  theme_light() +
  xlab("") +
  ylab("") +
  theme_void() +
  labs(caption = "Larger Circles Indicate More Bills",
       color = "Selection System",
       size = "# Bills") +
  scale_fill_discrete(name = "Selection System") 

# ggsave("bills by state and selection.jpeg")
```


Bills by selection system

```{r}
gavel %>%
  group_by(State, Elected) %>%
  count() %>%
  ungroup() %>%
  group_by(Elected) %>%
  summarize(mean_bills = mean(n)) %>%
  ggplot(aes(x = Elected, y = mean_bills)) +
  geom_col() +
  labs(x = "Selection System", y = "Average Number of Bills")

ggsave("number of bills by selection system.jpeg")

gavel %>%
  group_by(State, Elected, Year) %>%
  count() %>%
  ungroup() %>%
  ggplot(aes(x = n, color = Elected)) +
  geom_density() +
  labs(x = "Number of Bills in a Year", y = "Density", color = "Selection System")

ggsave("Density of Bills.jpeg")
```

```{r}
gavel %>%
  mutate(RichardLastAction = ifelse(RichardLastAction == "introduced", "Introduced", 
                                    RichardLastAction)) %>%
  count(RichardLastAction) %>%
  filter(!is.na(RichardLastAction)) %>%
  mutate(RichardLastAction = fct_reorder(RichardLastAction, n)) %>%
  ggplot(aes(x = RichardLastAction, y = n, label = n)) +
  geom_col() +
  geom_text(hjust = -0.5) +
  labs(x = "Final Action", y = "Number of Bills") +
  ylim(0,7500) +
  coord_flip() 

# ggsave("Bills by Last Action.jpeg")
```


# Text Analysis


## Unnesting the tokens
```{r}
tidy_text <- gavel %>%
  unnest_tokens(word, Description) %>%
  anti_join(stop_words)
```

```{r}
tidy_text %>%
  count(word, sort = TRUE)
```

```{r}
tidy_text %>%
  group_by(curbing, Type) %>%
  count(word, sort = TRUE) %>%
  filter(n > 75) %>%
  filter(curbing == 1) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = Type)) +
  geom_col() +
  xlab(NULL) +
  facet_wrap(~ Type, scales = "free_y") +
  coord_flip() 
```

```{r}
sentiments_bing_gavel <- tidy_text %>%
  inner_join(get_sentiments("bing"))
```

## Figuring out the incorrectly classified

I noticed that words like "Supreme" are getting classified as positive, when that is not really what should be going on.
```{r}
# word_bing <- sentiments_bing_gavel %>%
#   count(word, sentiment, sort = TRUE)

# write_csv(word_bing, "bing words.csv", na = "")
```


```{r}
# word_afinn <- sentiments_afinn_gavel %>%
#   count(word, value, sort = TRUE)

# write_csv(word_afinn, "afinn words.csv", na = "")
```

```{r}
# word_nrc <- tidy_text %>%
#   inner_join(get_sentiments("nrc"), by = "word") %>%
#   anti_join(stop_words) %>%
#   count(word, sentiment, sort = TRUE)

# write_csv(word_nrc, "nrc words.csv", na = "")
```

## Evaluating potential conflict words

NOTE: if labeled as "2", then it needs greater inspection

```{r}
custom_afinn <- read_csv("afinn words.csv")
custom_bing <- read_csv("bing words.csv")
custom_nrc  <- read_csv("nrc words.csv")
```

```{r}
custom_afinn1 <- custom_afinn %>%
  filter(!is.na(`Stop words`), `Stop words` == 1) %>%
  select(word)

custom_bing1 <- custom_bing %>%
  filter(!is.na(`Custom Stop`), `Custom Stop` == 1) %>%
  select(word)

custom_nrc1 <- custom_nrc %>%
  filter(!is.na(`Stop words`), `Stop words` == 1) %>%
  select(word)

custom_afinn_stop_words <- stop_words %>%
  select(word) %>%
  rbind(custom_afinn1)

custom_bing_stop_words <- stop_words %>%
  select(word) %>%
  rbind(custom_bing1)

custom_nrc_stop_words <- stop_words %>%
  select(word) %>%
  rbind(custom_nrc1)
```


```{r}
tidy_afinn_custom_stop <- tidy_text %>%
  anti_join(custom_afinn_stop_words, by = "word") %>%
  inner_join(get_sentiments("afinn"))
```

```{r}
tidy_bing_custom_stop <- tidy_text %>%
  anti_join(custom_bing_stop_words, by = "word") %>%
  inner_join(get_sentiments("bing"))
```




### Custom stop words datasets

Most common words in curbing legislation for afinn
```{r}
tidy_afinn_custom_stop %>%
  filter(curbing == 1) %>%
  count(word) %>%
  ungroup() %>%  
  filter(n > 10) %>%
  arrange(n) %>%
  mutate(word = factor(word, levels = unique(word))) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  labs(x = "", y = "Word Counts") +
  coord_flip()
```


```{r}
t_words <- tidy_afinn_custom_stop %>%
  count(value, Year, Elected) %>%
  mutate(weighted_value = value * n) %>%
  group_by(Year, Elected) %>%
  summarize(all_words = sum(n))


tidy_afinn_custom_stop %>%
  count(value, Year, Elected) %>%
  mutate(weighted_value = value * n) %>% 
  spread(value, n, fill = 0) %>%
  select(Year, Elected, weighted_value) %>%
  group_by(Year, Elected) %>%
  summarize(total_value = sum(weighted_value)) %>%
  left_join(t_words, by = c("Year", "Elected")) %>%
  mutate(proportion_value = total_value / all_words) %>%
  ggplot(aes(x = Year, y = proportion_value, fill = total_value > 0)) +
  geom_col() +
  facet_wrap(~Elected)
```

```{r}
tidy_afinn_custom_stop %>%
  count(Elected, word) %>%
  bind_tf_idf(word, Elected, n) %>%
  arrange(desc(tf_idf)) %>%
  group_by(Elected) %>%
  top_n(20, tf_idf) %>%
  ungroup() %>%
  mutate(word = reorder(word, tf_idf)) %>%
  ggplot(aes(x = word, y = tf_idf, fill = Elected)) +
  geom_col() +
  facet_wrap(~Elected, scales = "free_y") +
  coord_flip() +
  labs(title = "All Bills")

tidy_afinn_custom_stop %>%
  filter(curbing == 1) %>%
  count(Elected, word) %>%
  bind_tf_idf(word, Elected, n) %>%
  arrange(desc(tf_idf)) %>%
  group_by(Elected) %>%
  filter(tf_idf > 0.0025) %>%
  ungroup() %>%
  mutate(word = reorder(word, tf_idf)) %>%
  ggplot(aes(x = word, y = tf_idf, fill = Elected)) +
  geom_col() +
  facet_wrap(~Elected, scales = "free") +
  coord_flip() +
  labs(title = "Curbing Legislation only")
```



## What about bigrams?

```{r}
filtered_bigrams <- gavel %>%
  unnest_tokens(bigram, Description, token = "ngrams", n = 2) %>%
  separate(bigram, c("word1", "word2"), sep = " ") %>%
  filter(!word1 %in% custom_afinn_stop_words$word) %>%
  filter(!word2 %in% custom_afinn_stop_words$word) %>%
  unite(bigram, word1, word2, sep = " ")
```


```{r}
filtered_bigrams %>%
  count(Elected, bigram) %>%
  bind_tf_idf(bigram, Elected, n) %>%
  arrange(desc(tf_idf)) %>%
  group_by(Elected) %>%
  top_n(20, tf_idf) %>%
  ungroup() %>%
  mutate(bigram = reorder(bigram, tf_idf)) %>%
  ggplot(aes(x = bigram, y = tf_idf, fill = Elected)) +
  geom_col() +
  facet_wrap(~Elected, scales = "free_y") +
  coord_flip() +
  labs(title = "All Bills")

filtered_bigrams %>%
  filter(curbing == 1) %>%
  count(Elected, bigram) %>%
  bind_tf_idf(bigram, Elected, n) %>%
  arrange(desc(tf_idf)) %>%
  group_by(Elected) %>%
  top_n(20, tf_idf) %>%
  ungroup() %>%
  mutate(bigram = reorder(bigram, tf_idf)) %>%
  ggplot(aes(x = bigram, y = tf_idf, fill = Elected)) +
  geom_col() +
  facet_wrap(~Elected, scales = "free_y") +
  coord_flip() +
  labs(title = "Curbing Legislation")
```


### Sentiment Analysis of Bigrams


```{r}
filtered_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ") %>%
  inner_join(get_sentiments("bing"), by = c("word1" = "word")) %>%
  unite("bigram", c(word1, word2), sep = " ") %>%
  rename(sentiment_word1 = "sentiment") %>%
  group_by(Elected, Year) %>%
  count(sentiment_word1) %>%
  spread(sentiment_word1, n) %>%
  mutate(negative = ifelse(is.na(negative), 0, negative), 
         net_sentiment = (positive - negative)/(negative + positive)) %>%
  filter(Year != 2007) %>%
  ggplot(aes(x = Year, y = net_sentiment, color = Elected)) +
  geom_line() +
  scale_x_continuous(breaks = c(2008, 2010, 2012, 2014, 2016)) +
  labs(title = "Sentiment of First Word")
```

```{r}
filtered_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ") %>%
  inner_join(get_sentiments("bing"), by = c("word2" = "word")) %>%
  unite("bigram", c(word1, word2), sep = " ") %>%
  rename(sentiment_word2 = "sentiment") %>%
  group_by(Elected, Year) %>%
  count(sentiment_word2) %>%
  spread(sentiment_word2, n) %>%
  mutate(negative = ifelse(is.na(negative), 0, negative), 
         net_sentiment = (positive - negative)/(negative + positive)) %>%
  filter(Year != 2007) %>%
  ggplot(aes(x = Year, y = net_sentiment, color = Elected)) +
  geom_line() +
  scale_x_continuous(breaks = c(2008, 2010, 2012, 2014, 2016)) +  
  labs(title = "Sentiment of Second Word")
```

```{r}
filtered_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ") %>%
  filter(!(word1 %in% c("supreme", "merit", "partisan"))) %>%
  filter(curbing == 1) %>%
  inner_join(get_sentiments("bing"), by = c("word1" = "word")) %>%
  unite("bigram", c(word1, word2), sep = " ") %>%
  rename(sentiment_word1 = "sentiment") %>%
  count(bigram, sentiment_word1, Elected) %>%
  group_by(sentiment_word1, Elected) %>%
  filter(n > 2) %>%
  ggplot(aes(x = bigram, y = n, fill = sentiment_word1)) +
  geom_col() +
  coord_flip() +
  facet_wrap(Elected~sentiment_word1, scales = "free") +
  labs(title = "Most Common Positive and Negative Words in Curbing Legislation \nof First Word")
```


There is still SOOOO much processing that needs to happen.. These legal words are so messy.  This last graph is better, but it still needs work.  This should really be up above.


## Network plots


```{r}
library(widyr)
library(igraph)
library(ggraph)

set.seed(051319)


bigrams_count <- filtered_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ") %>%
  count(word1, word2, sort = TRUE)



bigrams_count %>%
  filter(n > 100) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link() +
  geom_node_point() +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1)

```




## Weighted Log Odds

```{r}
library(remotes)
install_github("juliasilge/tidylo")
library(tidylo)
```

```{r}
word_count <- tidy_afinn_custom_stop %>%
  count(MoreDefined, word, sort = TRUE)
```


```{r}
more_defined_log_odds <- word_count %>%
  bind_log_odds(MoreDefined, word, n) %>%
  arrange(desc(log_odds))

more_defined_log_odds %>%
  group_by(MoreDefined) %>%
  top_n(20, log_odds) %>%
  ungroup() %>%
  mutate(word = reorder_within(word, log_odds, MoreDefined)) %>%
  ggplot(aes(x = word, y = log_odds, fill = MoreDefined)) +
  geom_col() +
  facet_wrap(~ MoreDefined, scales = "free_y") +
  scale_x_discrete(labels = function(x) str_remove(x, "\\___.*")) +
  coord_flip()
```

```{r}
word_count_broad <- tidy_afinn_custom_stop %>%
  count(Elected,  word, sort = TRUE)

broad_log_odds <- word_count_broad %>%
  bind_log_odds(Elected, word, n) %>%
  arrange(desc(log_odds))
  
broad_log_odds %>%
  group_by(Elected) %>%
  top_n(20, log_odds) %>%
  ungroup() %>%
  mutate(word = reorder_within(word, log_odds, Elected)) %>%
  ggplot(aes(x = word, y = log_odds, fill = Elected)) +
  geom_col() +
  facet_wrap(~ Elected, scales = "free_y") +
  scale_x_discrete(labels = function(x) str_remove(x, "\\___.*")) +
  coord_flip()
```


```{r}
broad_log_odds %>%
  group_by(Elected) %>%
  top_n(25, n) %>%
  ggplot(aes(x = n, y = log_odds, label = word, color = Elected)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "red", lty = 2) +
  ggrepel::geom_text_repel() +
  scale_x_log10() +
  facet_wrap(~ Elected, scales = "free_x")
```


### Bill Type Log Odds

```{r}
bill_type <- gavel %>%
  select(Fullstate, Type, Description) %>%
  unnest_tokens(word, Description) %>%
  count(word, Type, Fullstate, sort = TRUE)

bill_type_log_odds <- bill_type %>%
  bind_log_odds(Type, word, n) %>%
  arrange(desc(log_odds))

bill_type_log_odds %>%
  group_by(Type) %>%
  top_n(20, log_odds) %>%
  ungroup() %>%
  mutate(word = reorder_within(word, log_odds, Type)) %>%
  ggplot(aes(x = word, y = log_odds, fill = Type)) +
  geom_col() +
  facet_wrap(~ Type, scales = "free_y") +
  scale_x_discrete(labels = function(x) str_remove(x, "\\___.*")) +
  coord_flip()
```



















## ACTUALLY SUPPORTIVE GRAPHS

I am now going to use the BING dictionary which seems to be showing what I am looking for (showing actual results instead of noise)

```{r}
tidy_bing_custom_stop <- tidy_bing_custom_stop %>%
  left_join(professional, by = c("Fullstate" = "State")) %>%
  left_join(political_culture, by = c("Fullstate" = "State")) %>%
  left_join(legislative_control, by = c("Fullstate" = "State")) %>%
  select(-Year.y) %>%
  rename(Year = "Year.x")
```




Below are weighted totals (weighted by the prevelance of the relevant variables).  Generally, the hope is to find that elected courts are almost always discussed more negatively than appointed.

Using bing dictionary, how are elected courts discussed?
```{r}
tidy_bing_custom_stop %>%
  filter(word != "crime") %>%
  count(sentiment, Year, Elected, word) %>%
  mutate(sentiment = ifelse(sentiment == "negative", -1, 1),
         net_sentiment = sentiment * n) %>%
  add_count(Year, Elected) %>%
  group_by(Year, Elected) %>%
  # mutate(proportional_sentiment = net_sentiment / n) %>%
  # summarize(total_value = sum(proportional_sentiment)) %>%
  summarize(total_value = sum(net_sentiment)) %>%
  ggplot(aes(x = Year, y = total_value, color = Elected)) +
  geom_line() +
  scale_x_continuous(breaks = c(2008, 2010, 2012, 2014, 2016)) +
  labs(y = "Net Sentiment", caption = "Using Bing Dictionary", color = "Selection System")

# ggsave("Net sentiment by selection.jpeg")
```

What about selection system AND ideologically distant?
```{r}
tidy_bing_custom_stop %>%
  filter(word != "crime") %>%
  count(sentiment, Year, outside, Elected, word) %>%
  mutate(sentiment = ifelse(sentiment == "negative", -1, 1),
         net_sentiment = sentiment * n) %>%
  add_count(Year, outside, Elected) %>%
  group_by(Year, outside, Elected) %>%
  mutate(proportional_sentiment = net_sentiment / n) %>%
  summarize(total_value = sum(proportional_sentiment)) %>%
  ggplot(aes(x = Year, y = total_value, color = Elected, lty = as.factor(outside))) +
  geom_line() +
  scale_x_continuous(breaks = c(2008, 2010, 2012, 2014, 2016)) +
  labs(y = "Net Sentiment", lty = "Ideologically Distant?", caption = "Using Bing Dictionary")
  
tidy_bing_custom_stop %>%
  filter(word != "crime") %>%
  count(sentiment, Year, outside, Elected, word) %>%
  mutate(sentiment = ifelse(sentiment == "negative", -1, 1),
         net_sentiment = sentiment * n) %>%
  add_count(Year, outside, Elected) %>%
  group_by(Year, outside, Elected) %>%
  mutate(proportional_sentiment = net_sentiment / n) %>%
  ungroup() %>%
  mutate(outside = ifelse(outside == 1, "Distant", "Not Distant")) %>%
  group_by(Year, outside, Elected) %>%
  # summarize(total_value = sum(proportional_sentiment)) %>%
  summarize(total_value = sum(net_sentiment)) %>%
  ggplot(aes(x = Year, y = total_value, color = Elected)) +
  geom_line() +
  scale_x_continuous(breaks = c(2008, 2010, 2012, 2014, 2016)) +
  labs(y = "Net Sentiment", color = "Selection System", caption = "Using Bing Dictionary") +
  facet_wrap(~outside)

# ggsave("net sentiment by ideology and selection.jpeg")
```

Now let's take a more refined view of ideological distnace.  It appears that there really isn't much going on here between ideological distnace and net sentiment:
```{r}
tidy_bing_custom_stop %>%
  count(sentiment, `Bill Number`, State, Year, upper, lower, judicial, word, Year, Elected) %>%
  mutate(sentiment = ifelse(sentiment == "negative", -1, 1),
         net_sentiment = sentiment * n) %>%
  group_by(State, Year, upper, lower, judicial, Elected) %>%
  summarize(total_sentiment = sum(net_sentiment)) %>%
  mutate(lower_dist = abs(lower - judicial),
         upper_dist = abs(upper - judicial)) %>%
  ggplot(aes(lower_dist, total_sentiment, color = Elected)) +
  geom_point() +
  geom_smooth() +
  labs(x = "Ideological Distance: Lower Chamber", y = "Net Sentiment", color = "Selection System")

# ggsave("ideological distance (lower) and sentiment as scatterplot.jpeg")

tidy_bing_custom_stop %>%
  count(sentiment, `Bill Number`, State, Year, upper, lower, judicial, word, Year, Elected) %>%
  mutate(sentiment = ifelse(sentiment == "negative", -1, 1),
         net_sentiment = sentiment * n) %>%
  group_by(State, Year, upper, lower, judicial, Elected) %>%
  summarize(total_sentiment = sum(net_sentiment)) %>%
  mutate(lower_dist = abs(lower - judicial),
         upper_dist = abs(upper - judicial)) %>%
  ggplot(aes(upper_dist, total_sentiment, color = Elected)) +
  geom_point() +
  geom_smooth() +
  labs(x = "Ideological Distance: Upper Chamber", y = "Net Sentiment", color = "Selection System")


# ggsave("ideological distance (upper) and sentiment as scatterplot.jpeg")
```


```{r}
tidy_bing_custom_stop %>%
  count(sentiment, Type, word) %>%
  mutate(sentiment = ifelse(sentiment == "negative", -1, 1),
         net_sentiment = sentiment * n) %>%
  add_count(Type) %>%
  group_by(Type) %>%
  mutate(proportional_sentiment = net_sentiment / n) %>%
  summarize(total_value = sum(proportional_sentiment)) %>%
  mutate(Type = fct_reorder(Type, total_value)) %>%
  ggplot(aes(x = Type, y = total_value)) +
  geom_col() +
  labs(x = "Bill Type", y = "Net Sentiment", caption = "Using Bing Dictionary") +
  coord_flip()

# ggsave("sentiment by bill type.jpeg")
```

Sentiment by Bill type.  Takeaway: in every time, the elected is more negative than the appointed.
```{r}
tidy_bing_custom_stop %>%
  filter(word != "crime") %>%
  count(sentiment, Type, word, Elected) %>%
  mutate(sentiment = ifelse(sentiment == "negative", -1, 1),
         net_sentiment = sentiment * n) %>%
  add_count(Type, Elected) %>%
  group_by(Type, Elected) %>%
  # mutate(proportional_sentiment = net_sentiment / n) %>%
  # summarize(total_value = sum(proportional_sentiment)) %>%
  summarize(total_value = sum(net_sentiment)) %>%
  ungroup() %>%
  mutate(Type = fct_reorder(Type, total_value)) %>%
  ggplot(aes(x = Type, y = total_value, fill = Elected)) +
  geom_col(position = "dodge") +
  labs(x = "", y = "Net Sentiment", fill = "Selection System") +
  coord_flip()

# ggsave("sentiment by type and selection.jpeg")
```




Next is to do the same graphs but curbing, then start the write up

```{r}
tidy_bing_custom_stop %>%
  filter(word != "crime") %>%
  count(sentiment, curbing, word) %>%
  mutate(sentiment = ifelse(sentiment == "negative", -1, 1),
         net_sentiment = sentiment * n) %>%
  add_count(curbing) %>%
  group_by(curbing) %>%
  mutate(proportional_sentiment = net_sentiment / n) %>%
  summarize(total_value = sum(proportional_sentiment)) %>%
  ungroup() %>%
  filter(!is.na(curbing)) %>%
  ggplot(aes(x = as.factor(curbing), y = total_value, fill = as.factor(curbing))) +
  geom_col() +
  coord_cartesian(ylim = c(-2, 2)) +
  labs(fill = "court curbing")
```





```{r}
tidy_bing_custom_stop %>%
  filter(word != "crime") %>%
  count(sentiment, curbing, word, Elected) %>%
  mutate(sentiment = ifelse(sentiment == "negative", -1, 1),
         net_sentiment = sentiment * n) %>%
  add_count(curbing, Elected) %>%
  group_by(curbing, Elected) %>%
  mutate(proportional_sentiment = net_sentiment / n) %>%
  summarize(total_value = sum(proportional_sentiment)) %>%
  ungroup() %>%
  filter(!is.na(curbing)) %>%
  ggplot(aes(x = Elected, y = total_value, fill = as.factor(curbing))) +
  geom_col(position = "dodge") +
  coord_cartesian(ylim = c(-2, 2)) +
  labs(fill = "Court Curbing")
```


```{r}
tidy_bing_custom_stop %>%
  filter(word != "crime") %>%
  filter(sentiment == "positive") %>%
  unite(id, c("State", "Bill Number", "Year"), sep = " ") %>%
  pairwise_count(word, id, sort = TRUE) %>%
  filter(n > 3) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link() +
  geom_node_point() +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1)
```


```{r}
tidy_bing_custom_stop %>%
  filter(word != "crime") %>%
  filter(sentiment == "negative") %>%
  unite(id, c("State", "Bill Number", "Year"), sep = " ") %>%
  pairwise_count(word, id, sort = TRUE) %>%
  filter(n > 5) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link() +
  geom_node_point() +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void()
```


```{r}
tidy_bing_custom_stop %>%
  count(sentiment, Year, Elected, word, State) %>%
  mutate(sentiment = ifelse(sentiment == "negative", -1, 1),
         net_sentiment = sentiment * n) %>%
  group_by(Year, Elected, State) %>%
  summarize(total_value = sum(net_sentiment)) %>%
  statebins_continuous(state_col = "State",
                     text_color = "white", value_col = "total_value",
                     brewer_pal="Reds", font_size = 3,
                     legend_title="Test") 
```





```{r}
tidy_bing_custom_stop %>%
  filter(word != "crime") %>%
  count(sentiment, Year, Elected, word, State) %>%
  mutate(sentiment = ifelse(sentiment == "negative", -1, 1),
         net_sentiment = sentiment * n) %>%
  add_count(Year, Elected) %>%
  group_by(Year, Elected, State) %>%
  # mutate(proportional_sentiment = net_sentiment / n) %>%
  # summarize(total_value = sum(proportional_sentiment)) %>%
  summarize(total_value = sum(net_sentiment)) %>%
  arrange(State) %>%
  ggplot(aes(x = Year, y = total_value, color = Elected)) +
  geom_line() +
  theme_bw() +
  labs(y = "Net Sentiment", color = "Selection System") +
  scale_x_continuous(breaks = c(2008, 2012, 2016), labels = c("'08", "'12", "1'6")) +
  # scale_y_continuous(breaks = c(0, -.2)) +
  facet_geo(~State, grid =  "us_state_grid3")

# ggsave("facet_geo of sentiment over space and time.jpeg")
```




#### Control Variables

Professional
```{r}
tidy_bing_custom_stop %>%
  # filter(word != "crime") %>%
  mutate(sentiment = ifelse(sentiment == "negative", -1, 1)) %>%
  # add_count(Professionalization) %>%
  group_by(State, Professionalization) %>%
  summarize(total_sentiment = sum(sentiment)) %>%
  ungroup() %>%
  group_by(Professionalization) %>%
  summarise(mean_sentiment = mean(total_sentiment)) %>%
  # mutate(proportional_sentiment = total_sentiment / n) %>%
  # ggplot(aes(x = Professionalization, y = proportional_sentiment)) +
  ggplot(aes(x = factor(Professionalization), y = mean_sentiment)) +
  geom_col() +
  labs(x = "Level of Professionalization", y = "Mean Net Sentiment") +
  scale_x_discrete(breaks = c(1, 2, 3, 4, 5),
                   labels = c("Least \nProfessional", "2", "3", "4", "Most \nProfessional"))

# ggsave("professionalization.jpeg")
```

political culture
```{r}
tidy_bing_custom_stop %>%
  # filter(word != "crime") %>%
  mutate(sentiment = ifelse(sentiment == "negative", -1, 1),
         culture = ifelse(Moralistic  == 1, "Moralistic",
                          ifelse(Traditionalistic == 1, "Traditionalistic",
                                 "Individualistic"))) %>%
  group_by(culture, State) %>%
  summarize(total_sentiment = sum(sentiment)) %>%
  ungroup() %>%
  filter(!(is.na(culture))) %>%
  group_by(culture) %>%
  summarise(mean_sentiment = mean(total_sentiment)) %>%
  spread(culture, mean_sentiment) %>%
  mutate(diff_individual = (Individualistic - Moralistic),
         diff_traditional = (Traditionalistic - Moralistic)) %>%
  select(-Individualistic, -Moralistic, -Traditionalistic) %>%
  gather(type, value) %>%
  # ggplot(aes(x = culture, y = proportional_sentiment)) +
  ggplot(aes(x = factor(type), y = value)) +
  geom_col() +
  labs(x = "Political Culture", 
       y = "Differences in Mean Net Sentiment") +
  scale_x_discrete(labels = c("Individualistic - Moralistic", "Traditionalistic - Moralistic"))

# ggsave("political culture.jpeg")
```

```{r}
tidy_bing_custom_stop %>%
  filter(word != "crime") %>%
  mutate(unified = ifelse(SplitLegislature == 0, 1, 0),
         sentiment = ifelse(sentiment == "negative", -1, 1)) %>%
  add_count(unified) %>% 
  group_by(unified, n) %>%
  summarize(total_sentiment = sum(sentiment)) %>%
  ungroup() %>%
  mutate(proportional_sentiment = total_sentiment / n) %>%
  filter(!(is.na(unified))) %>%
  ggplot(aes(x = as.factor(unified), y = proportional_sentiment)) +
  geom_col() +
  labs(x = "Unified Legislative Control", y = "Net Sentiment") +
  scale_x_discrete(labels = c("No", "Yes"))

# ggsave("unified.jpeg")
```


## Data for OLS

Creating the DV and main IV
```{r}
ols_data <- tidy_bing_custom_stop %>%
  filter(word != "crime") %>%
  count(sentiment, Year, Elected, word, Fullstate) %>%
  mutate(sentiment = ifelse(sentiment == "negative", -1, 1),
         net_sentiment = sentiment * n) %>%
  # add_count(Year, Elected) %>%
  group_by(Year, Elected, Fullstate) %>%
  # mutate(proportional_sentiment = net_sentiment / n) %>%
  # summarize(total_value = sum(proportional_sentiment)) %>%
  summarize(total_value = sum(net_sentiment))
```

Preparing an object for ideology
```{r}
ideology <- gavel %>%
  select(Fullstate, Year, judicial, lower, upper, outside) %>%
  distinct()
```


joining the different tables to create the csv file called `model_data.csv`.
```{r}
ols_data <- ols_data %>%
  left_join(legislative_control, 
            by = c("Fullstate" = "State", "Year")) %>%
  left_join(political_culture, by = c("Fullstate" = "State")) %>%
  left_join(professional, by = c("Fullstate" = "State")) %>%
  left_join(ideology, by = c("Fullstate", "Year"))

# write.csv(ols_data, "model_data.csv")
```


## Data for OLS of curbing

```{r}
tidy_text_curbing <- gavel %>%
  filter(curbing == 1) %>%
  unnest_tokens(word, Description) %>%
  anti_join(stop_words)

court_curbing_text <- tidy_text_curbing %>%
  anti_join(custom_bing_stop_words, by = "word") %>%
  inner_join(get_sentiments("bing")) %>%
  mutate(sentiment = ifelse(sentiment == "negative", -1, 1)) %>%
  group_by(State, Year) %>%
  summarise(total_sentiment = sum(sentiment)) %>%
  ungroup() %>%
  complete(Year, State, fill = list(total_sentiment = 0))

# write.csv(court_curbing_text, "curbing_model_data.csv")
```




